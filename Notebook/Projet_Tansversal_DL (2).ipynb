{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMw5NkgauP8M"
      },
      "source": [
        "# Classification des images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H6Lf7YklfHr"
      },
      "source": [
        "Le projet consiste à développer un modèle de classification multi-classes d'images de champs de maïs, capturées à l'aide d'un smartphone, afin de simuler une vue depuis une machine de pulvérisation équipée d'une caméra. L'objectif est d'identifier les zones à arroser en distinguant quatre classes principales : sol sec sans végétation (ground), végétation de maïs (corn), plantes herbacées diverses (weeds), et une combinaison de maïs et de mauvaises herbes (corn/weeds)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQHJHW_EzjVT"
      },
      "source": [
        "## Import librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBXbPdxJt6aj",
        "outputId": "645cbea3-078c-4373-d5c4-92a8c883003b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8vqRlhLfuOnG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.applications import VGG19, Xception\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import lime\n",
        "import lime.lime_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F48Qe7kbF80t"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cSSYmOhILaFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6aaad7-5029-4723-d38b-43077b77689e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BebhnUWeMUE"
      },
      "source": [
        "##Data Exploration and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5Vto47QA3LjE"
      },
      "outputs": [],
      "source": [
        "# Chemins vers les dossiers contenant les images de chaque classe\n",
        "folder_Chaos_train = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Treino/Chao\"\n",
        "folder_Ervas_train = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Treino/Ervas\"\n",
        "folder_Milho_train = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Treino/Milho\"\n",
        "folder_Milho_ervas_train = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Treino/Milho_ervas\"\n",
        "\n",
        "folder_Chaos_test = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Teste/Chao\"\n",
        "folder_Ervas_test = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Teste/Ervas\"\n",
        "folder_Milho_test = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Teste/Milho\"\n",
        "\n",
        "folder_Chaos_val = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Valida+º+úo/Chao\"\n",
        "folder_Ervas_val = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Valida+º+úo/Ervas\"\n",
        "folder_Milho_val = \"/content/drive/MyDrive/Kaggle/ImagensTCCRotuladas/Valida+º+úo/Milho\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWfVCDvBOuP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def load_images_by_batches(folder_path, target_size=(224, 224)):\n",
        "    ims = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n",
        "    random.shuffle(ims)  # Mélanger aléatoirement les images\n",
        "    ims = ims[:int(len(ims) * 0.14)]  # Sélectionner 14% des images\n",
        "    X_batches = []\n",
        "    y_batches = []\n",
        "    label = os.path.basename(folder_path)  # Obtenir le nom du dossier parent comme étiquette\n",
        "    for image_path in ims:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, target_size)  # Redimensionner l'image\n",
        "        X_batches.append(image)\n",
        "        y_batches.append(label)  # Utiliser le nom du dossier comme étiquette\n",
        "    return X_batches, y_batches\n",
        "\n",
        "# Charger les images et créer les étiquettes pour chaque classe\n",
        "X_Chaos_batches_train, y_Chaos_batches_train = load_images_by_batches(folder_Chaos_train)\n",
        "X_Ervas_batches_train, y_Ervas_batches_train = load_images_by_batches(folder_Ervas_train)\n",
        "X_Milho_batches_train, y_Milho_batches_train = load_images_by_batches(folder_Milho_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq7WjWsde1cJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Sélectionner une image aléatoire de chaque classe\n",
        "Chao_img_name = random.choice(os.listdir(folder_Chaos_train))\n",
        "Ervas_img_name = random.choice(os.listdir(folder_Ervas_train))\n",
        "Milho_img_name = random.choice(os.listdir(folder_Milho_train))\n",
        "Milho_ervas_img_name = random.choice(os.listdir(folder_Milho_ervas_train))\n",
        "\n",
        "# Chemins complets des images\n",
        "Chao_img_path = os.path.join(folder_Chaos_train, Chao_img_name)\n",
        "Ervas_img_path = os.path.join(folder_Ervas_train, Ervas_img_name)\n",
        "Milho_img_path = os.path.join(folder_Milho_train, Milho_img_name)\n",
        "Milho_ervas_img_path = os.path.join(folder_Milho_ervas_train, Milho_ervas_img_name)\n",
        "\n",
        "# Lire les images\n",
        "Chao_img = mpimg.imread(Chao_img_path)\n",
        "Ervas_img = mpimg.imread(Ervas_img_path)\n",
        "Milho_img = mpimg.imread(Milho_img_path)\n",
        "Milho_ervas_img = mpimg.imread(Milho_ervas_img_path)\n",
        "\n",
        "# Afficher les images\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(Chao_img)\n",
        "plt.title('Chao')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(Ervas_img)\n",
        "plt.title('Ervas')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(Milho_img)\n",
        "plt.title('Milho')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(Milho_ervas_img)\n",
        "plt.title('Milho_ervas')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHQZ_xOjGEzL"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wRgams3k1b7"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "# Fonction pour redimensionner une image\n",
        "def resize_image(image_path, new_size=(128, 128)):\n",
        "    image = mpimg.imread(image_path)\n",
        "    resized_image = resize(image, new_size)\n",
        "    return resized_image\n",
        "\n",
        "# Redimensionner les images\n",
        "new_size = (128, 128)\n",
        "Chao_img = resize_image(Chao_img_path, new_size)\n",
        "Ervas_img = resize_image(Ervas_img_path, new_size)\n",
        "Milho_img = resize_image(Milho_img_path, new_size)\n",
        "Milho_ervas_img = resize_image(Milho_ervas_img_path, new_size)\n",
        "\n",
        "# Afficher les images\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(Chao_img)\n",
        "plt.title('Chao')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(Ervas_img)\n",
        "plt.title('Ervas')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(Milho_img)\n",
        "plt.title('Milho')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(Milho_ervas_img)\n",
        "plt.title('Milho_ervas')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx0xlwkzdQYK"
      },
      "outputs": [],
      "source": [
        "# Charger les images pour l'entraînement, le test et la validation\n",
        "X_Chaos_train, y_Chaos_train = load_images_by_batches(folder_Chaos_train)\n",
        "X_Ervas_train, y_Ervas_train = load_images_by_batches(folder_Ervas_train)\n",
        "X_Milho_train, y_Milho_train = load_images_by_batches(folder_Milho_train)\n",
        "\n",
        "X_Chaos_test, y_Chaos_test = load_images_by_batches(folder_Chaos_test)\n",
        "X_Ervas_test, y_Ervas_test = load_images_by_batches(folder_Ervas_test)\n",
        "X_Milho_test, y_Milho_test = load_images_by_batches(folder_Milho_test)\n",
        "\n",
        "X_Chaos_val, y_Chaos_val = load_images_by_batches(folder_Chaos_val)\n",
        "X_Ervas_val, y_Ervas_val = load_images_by_batches(folder_Ervas_val)\n",
        "X_Milho_val, y_Milho_val = load_images_by_batches(folder_Milho_val)\n",
        "\n",
        "# Concaténer les ensembles de données en un seul tableau\n",
        "X_train = np.concatenate((X_Chaos_train, X_Ervas_train, X_Milho_train), axis=0)\n",
        "y_train = np.concatenate((y_Chaos_train, y_Ervas_train, y_Milho_train), axis=0)\n",
        "\n",
        "X_test = np.concatenate((X_Chaos_test, X_Ervas_test, X_Milho_test), axis=0)\n",
        "y_test = np.concatenate((y_Chaos_test, y_Ervas_test, y_Milho_test), axis=0)\n",
        "\n",
        "X_val = np.concatenate((X_Chaos_val, X_Ervas_val, X_Milho_val), axis=0)\n",
        "y_val = np.concatenate((y_Chaos_val, y_Ervas_val, y_Milho_val), axis=0)\n",
        "\n",
        "# Normalisation des données\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_val = X_val / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_suBcah7Vg-e"
      },
      "outputs": [],
      "source": [
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aQKngcw08cp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convertir les étiquettes en catégories (encodage one-hot)\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdLW5PA3oCEf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convertir les noms de classe en nombres entiers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Convertir les nombres entiers en encodage one-hot\n",
        "y_train = to_categorical(y_train_encoded, num_classes)\n",
        "y_test = to_categorical(y_test_encoded, num_classes)\n",
        "y_val = to_categorical(y_val_encoded, num_classes)\n",
        "\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h--zIfdlBEx"
      },
      "source": [
        "Prétraitement des données:\n",
        "\n",
        "\n",
        "1.   Redimensionnement en 128 x128 et normalisation de l'image\n",
        "  en niveaux de gris avec 255.0\n",
        "2.   Séparation du jeu de données en 3 parties: entraînement, validation, test.\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE6kxWhEeb83"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTUY_1ht-tq"
      },
      "source": [
        "Les filtres de taille 3x3 sont  utilisés dans les CNN car ils ont une taille suffisamment petite pour capturer des motifs locaux tout en conservant suffisamment d'informations spatiales.\n",
        "Fonction d'activation ReLU :\n",
        "\n",
        "La fonction d'activation ReLU introduit une non-linéarité dans le modèle, ce qui permet au réseau d'apprendre des représentations plus complexes et non linéaires des données.\n",
        "\n",
        "Batch Normalization\n",
        " aide à stabiliser et accélérer l'apprentissage, en réduisant les effets du changement de distribution des données à chaque couche.\n",
        "Pooling (MaxPooling) :\n",
        "\n",
        "réduire la dimensionnalité des cartes de caractéristiques, tout en préservant les informations les plus importantes.\n",
        "\n",
        "Flattening :\n",
        "\n",
        "convertir les cartes de caractéristiques bidimensionnelles en un vecteur unidimensionnel afin de les alimenter dans les couches entièrement connectées.\n",
        "Dropout :0.5 est appliqué après la couche entièrement connectée pour réduire la co-adaptation des neurones.\n",
        "Optimiseur Adam :\n",
        "\n",
        "L'optimiseur Adam  combine des techniques d'optimisation adaptatives avec l'estimation des moments d'ordre supérieur pour converger plus rapidement et de manière plus stable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYuVZVu6gGN8"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gmyZYQqwUG7"
      },
      "outputs": [],
      "source": [
        "# Création du modèle CNN\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout des couches\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Ajout de la couche de flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# Ajout des couches fully connected\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tV1ejdvwK3-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO8dlTGJgaFf"
      },
      "source": [
        "### Fit with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXB5I1BBoMVR"
      },
      "outputs": [],
      "source": [
        "# Entraînement du modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Évaluation du modèle sur l'ensemble de test\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGcEQZFco3B7"
      },
      "source": [
        "## Evaluation la performance des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abiprj_fo5IU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foKIQIxmHTkK"
      },
      "source": [
        "Les courbes d'accuracy et de loss sur les ensembles d'entraînement et de validation pour observer la performance du modèle au fil des époques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tLmwqO41Xf"
      },
      "source": [
        "la précision de l’entraînement est beaucoup plus élevée que la précision de la validation, cela peut indiquer un surapprentissage, c’est-à-dire que le modèle a trop appris les détails spécifiques des données d’entraînement et ne généralise pas bien à de nouvelles Images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pq2WaqZejbP"
      },
      "source": [
        "## Expérimentations  optimiseurs  Adam, RMSprop, Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z7nGUwjw0Bl"
      },
      "source": [
        "Nous conservons les autres parametres dans les trois cas d'expérimentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n35MmMVRxCce"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "num_classes = 3\n",
        "# Création du modèle CNN\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout des couches\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP2tlp1hwkI7"
      },
      "source": [
        "### Adam\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkuatoYYGmj4"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle avec l'optimiseur Adam\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Évaluation du modèle\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy with Adam optimizer: {}\".format(test_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpjJbH4cxzvd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOr0cuPhxRvm"
      },
      "source": [
        "### RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCbwOJ9exPGl"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle avec l'optimiseur Adam\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Évaluation du modèle\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy with Adam optimizer: {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ohZNX0BxyPl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h69mnJAxcjG"
      },
      "source": [
        "### Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hrDZnq8xY6h"
      },
      "outputs": [],
      "source": [
        "# Compilation du modèle avec l'optimiseur Adam\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Évaluation du modèle\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy with Adam optimizer: {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjkiK5yOxsaE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91G6Or1apvpl"
      },
      "source": [
        "## Expérimentations avec dropout en combinaison avec la normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m57RV26KWnLk"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dropout, BatchNormalization\n",
        "\n",
        "# Liste des taux de dropout à expérimenter\n",
        "dropout_rates = [0.2, 0.4, 0.6]\n",
        "\n",
        "for rate in dropout_rates:\n",
        "    # Ajout des couches\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Compilation du modèle\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Entraînement du modèle\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Évaluation du modèle\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(\"Test accuracy with dropout rate {}: {}\".format(rate, test_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2dw3yocfhQV"
      },
      "source": [
        "La fonction Dropout est utilisée pour régulariser le modèle CNN .Lors de l’entraînement du\n",
        "modèle, à chaque époque, la fonction Dropout désactive aléatoirement 20% ,40% ou 60% pourcentage de\n",
        "neurones dans une couche donnée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-XReT3An2nX"
      },
      "source": [
        "## Models préentrainés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_Nf5qMuXFAU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZUGh0XTXKdZ"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnB6LYiwgLBf"
      },
      "source": [
        "GG16 est un modèle de réseau de neurones convolutifs. Il est composé de 16 couches de\n",
        "convolution et de pooling, suivi de trois couches entièrement connectées. VGG16 est connu\n",
        "pour sa simplicité et sa capacité à extraire des caractéristiques pertinentes à partir d’images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1MnbqPg3Qb"
      },
      "source": [
        "#### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBEPRsukqjxH"
      },
      "outputs": [],
      "source": [
        "# Charger le modèle VGG16 pré-entraîné\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Geler les couches du modèle VGG16 pour éviter de ré-entraîner les poids\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Créer un nouveau modèle Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# Ajouter les couches du modèle VGG16\n",
        "model.add(vgg16_model)\n",
        "\n",
        "# Ajouter des couches supplémentaires pour la classification\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl2y27Epna5D"
      },
      "source": [
        "#### Fit with validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4xZhQARrgcE"
      },
      "outputs": [],
      "source": [
        "# Entraîner le modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzyi960Ox9W5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeVipurgnlox"
      },
      "source": [
        "### VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyavKTAKgVrn"
      },
      "source": [
        "VGG19 est une variante de VGG16 avec 19 couches de convolution. Il partage la même\n",
        "architecture de base, mais avec plus de paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSiDnh-bhGPQ"
      },
      "source": [
        "#### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh2ULZGbrpVx"
      },
      "outputs": [],
      "source": [
        "# Charger le modèle VGG19 pré-entraîné\n",
        "vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvs_nqizoZSG"
      },
      "source": [
        "#### Fit with validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATUHH9ZUyH0p"
      },
      "outputs": [],
      "source": [
        "# Entraîner le modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb-Wmf9RyBlj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmQR1NrasQco"
      },
      "source": [
        "### xception_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdCQSiJYgDri"
      },
      "source": [
        "Xception est un modèle de réseau de neurones profond qui a été développé comme une\n",
        "variante de l’architecture Inception. Il est basé sur des convolutions en profondeur et a étéconçu pour améliorer l’efficacité de calcul tout en maintenant de bonnes performances de\n",
        "classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNw74DSmyiJ6"
      },
      "source": [
        "####Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPl0uRI6sXWa"
      },
      "outputs": [],
      "source": [
        "# Charger le modèle Xception pré-entraîné\n",
        "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCEqYI-yxFS"
      },
      "source": [
        "#### Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PnJwz-pyf_P"
      },
      "outputs": [],
      "source": [
        "# Entraîner le modèle\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W6Oqhcvy9if"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tracer les courbes d'accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Tracer les courbes de loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBdiJAHTs0Qj"
      },
      "source": [
        "## Les images et la probabilité correspondant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v9L4NpGs14s"
      },
      "outputs": [],
      "source": [
        "# Sélectionner quelques images de chaque classe pour les tests supplémentaires\n",
        "# Assurez-vous de les prétraiter de la même manière que vos données d'entraînement\n",
        "\n",
        "# Faire des prédictions sur ces images avec le modèle entraîné\n",
        "y_pred = model.predict(X_selected_images)\n",
        "\n",
        "# Afficher les images avec les prédictions et les probabilités correspondantes\n",
        "for i in range(len(X_selected_images)):\n",
        "    plt.imshow(X_selected_images[i])\n",
        "    plt.title(\"Predicted class: {} (Probability: {:.2f})\".format(np.argmax(y_pred[i]), np.max(y_pred[i])))\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD_Ss2EGtjEC"
      },
      "source": [
        "## Lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjROiLMkth4Y"
      },
      "outputs": [],
      "source": [
        "# Utiliser LIME pour générer des superpixels explicatifs\n",
        "explainer = lime.lime_image.LimeImageExplainer()\n",
        "for i in range(len(X_selected_images)):\n",
        "    explanation = explainer.explain_instance(X_selected_images[i].astype('double'), model.predict, top_labels=5)\n",
        "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
        "    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "    plt.title(\"Superpixels explicatifs pour la prédiction de classe: {}\".format(np.argmax(y_pred[i])))\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}